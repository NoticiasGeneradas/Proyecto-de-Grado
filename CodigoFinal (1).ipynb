{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "136b5bdb-e0f8-4834-9fcb-d70c2605d06f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importar librerías necesarias\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense, Concatenate, Input\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90ceb337-2784-4f6d-8a91-b84472184dfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ruta actualizada del archivo\n",
    "file_path ='ruta del archivo'\n",
    "\n",
    "# Intentar leer el archivo y separar columnas\n",
    "try:\n",
    "    data = pd.read_csv(file_path, encoding='utf-8', delimiter=';')  # Probar primero con utf-8 y delimitador ;\n",
    "except UnicodeDecodeError:\n",
    "    data = pd.read_csv(file_path, encoding='latin1', delimiter=';') \n",
    "except FileNotFoundError:\n",
    "    print(\"El archivo no se encuentra en la ruta especificada. Verifica nuevamente.\")\n",
    "\n",
    "# Mostrar las primeras filas para verificar\n",
    "print(data.head())\n",
    "\n",
    "# Verificar si las columnas están separadas correctamente\n",
    "if 'text' not in data.columns:\n",
    "    print(\"Error: La columna 'text' no existe. Verifique el delimitador del archivo CSV.\")\n",
    "else:\n",
    "    print(\"Archivo cargado correctamente con las columnas esperadas.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1034017-36c4-4f32-a095-3cdc9517e054",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear una función para limpiar el texto\n",
    "def limpiar_texto(texto):\n",
    "    if isinstance(texto, str):  # Verificar si el texto es una cadena\n",
    "        texto = texto.lower()\n",
    "        texto = re.sub(r\"[^a-zA-Z0-9áéíóúñü\\s]\", \"\", texto)\n",
    "        return texto\n",
    "    return \"\"  # Retornar una cadena vacía si no es texto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc69ce6f-c304-4031-b0cd-dfc32e73a63d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear la columna clean_text\n",
    "data['clean_text'] = data['text'].apply(limpiar_texto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f506067-bc77-4ab6-a691-0b1755b19657",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Verificar las primeras filas para confirmar que la limpieza funcionó\n",
    "print(data[['text', 'clean_text']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02cbebf6-f715-4c4d-829f-f31680772be7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generar datos simulados para los equipos\n",
    "teams = [\"Real Madrid\", \"Barcelona\", \"Atlético Madrid\", \"Valencia\", \"Villarreal\", \"Sevilla\"]\n",
    "data_historica = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9279c05-f15b-4fb5-9184-fd9c7bf7cc8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Datos reales: posiciones históricas de los últimos 5 años\n",
    "posiciones_historicas = {\n",
    "    \"Real Madrid\": [1, 2, 1, 2, 1],\n",
    "    \"Barcelona\": [2, 1, 3, 1, 2],\n",
    "    \"Atlético Madrid\": [3, 3, 2, 3, 3],\n",
    "    \"Valencia\": [7, 9, 13, 4, 6],\n",
    "    \"Villarreal\": [5, 7, 5, 5, 4],\n",
    "    \"Sevilla\": [4, 4, 4, 6, 5]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18ac2e27-5489-4349-b0c3-095d2717976c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Datos reales: capacidad de los estadios (en miles de espectadores)\n",
    "capacidad_estadios = {\n",
    "    \"Real Madrid\": 81,\n",
    "    \"Barcelona\": 99,\n",
    "    \"Atlético Madrid\": 68,\n",
    "    \"Valencia\": 49,\n",
    "    \"Villarreal\": 23,\n",
    "    \"Sevilla\": 43\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4321e2c7-ae9b-4c65-93d2-8aa1c2207af3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generar datos simulados y calcular predicciones basadas en posiciones históricas\n",
    "for team in teams:\n",
    "    prob_victoria = round(random.uniform(0.5, 1.0), 2)  # Probabilidad entre 0.5 y 1.0\n",
    "    goles_favor = random.randint(0, 5)  # Goles promedio por partido\n",
    "    goles_contra = random.randint(0, 5)\n",
    "\n",
    "    # Predicción basada en posiciones históricas\n",
    "    posiciones = posiciones_historicas.get(team, [10, 10, 10, 10, 10])\n",
    "    prediccion_posicion = round(sum(posiciones) / len(posiciones))\n",
    "\n",
    "    # Capacidad del estadio\n",
    "    capacidad_estadio = capacidad_estadios.get(team, 30)  # Valor predeterminado si falta\n",
    "\n",
    "    data_historica.append({\n",
    "        \"team\": team,\n",
    "        \"prob_victoria\": prob_victoria,\n",
    "        \"goles_favor\": goles_favor,\n",
    "        \"goles_contra\": goles_contra,\n",
    "        \"posicion_tabla\": prediccion_posicion,\n",
    "        \"capacidad_estadio\": capacidad_estadio\n",
    "    })\n",
    "\n",
    "data_historica_df = pd.DataFrame(data_historica)\n",
    "print(\"Datos históricos y simulados con capacidad del estadio:\")\n",
    "print(data_historica_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fde344e-b6b9-4c7a-a726-5d095afdd75a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparar datos históricos para integrarlos con las noticias\n",
    "# Alinear los índices entre los datos históricos y las noticias\n",
    "if len(data) > len(data_historica_df):\n",
    "    data_historica_df = data_historica_df.sample(len(data), replace=True, random_state=42).reset_index(drop=True)\n",
    "\n",
    "data['historical_data'] = data_historica_df.apply(\n",
    "    lambda x: [x[\"prob_victoria\"], x[\"goles_favor\"], x[\"goles_contra\"], x[\"posicion_tabla\"], x[\"capacidad_estadio\"]], axis=1\n",
    ")\n",
    "data[\"historical_data\"] = data[\"historical_data\"].apply(lambda x: ','.join(map(str, x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df4893a4-e59a-437b-b85d-1c77e8a9e5f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenización del texto\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(data['clean_text'])\n",
    "tokenized_texts = tokenizer.texts_to_sequences(data['clean_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caa2c2ba-d699-41b0-b893-caefabfc8745",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creación de secuencias y padding\n",
    "seq_length = 50\n",
    "input_sequences = []\n",
    "historical_features = []\n",
    "targets = []\n",
    "\n",
    "for i, seq in enumerate(tokenized_texts):\n",
    "    for j in range(seq_length, len(seq)):\n",
    "        input_sequences.append(seq[j-seq_length:j])\n",
    "        targets.append(seq[j])\n",
    "        historical_features.append([float(val) for val in data['historical_data'].iloc[i].split(',')])\n",
    "\n",
    "input_sequences = np.array(pad_sequences(input_sequences, maxlen=seq_length))\n",
    "targets = np.array(targets)\n",
    "historical_features = np.array(historical_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c060ca3-21cf-4799-a15c-233f36fa113a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ajustar datos históricos para que coincidan con las secuencias\n",
    "historical_features_adjusted = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90c6799c-851b-4b57-a020-09c5dad6bc8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alinear correctamente los datos históricos con las secuencias\n",
    "for i in range(len(input_sequences)):\n",
    "    index = i % len(historical_features)  # Usar módulo para repetir los datos históricos\n",
    "    historical_features_adjusted.append(historical_features[index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "635aa1b6-879b-4cad-9228-124e48d88325",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convertir a array de numpy\n",
    "historical_features_adjusted = np.array(historical_features_adjusted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b10a81b-8afe-4739-9f12-73b9fb5cc420",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificar dimensiones\n",
    "print(f\"Dimensiones ajustadas de historical_features: {historical_features_adjusted.shape}\")\n",
    "print(f\"Dimensiones de input_sequences: {input_sequences.shape}\")\n",
    "print(f\"Dimensiones de targets: {targets.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d12f5f07-868e-40c3-8685-090d3af6662b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir el tamaño del vocabulario\n",
    "vocab_size = len(tokenizer.word_index) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1525103-a4a2-4740-99a8-838b2fd8ba27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir las entradas del modelo\n",
    "text_input = Input(shape=(seq_length,), name=\"text_input\")\n",
    "historical_input = Input(shape=(len(historical_features_adjusted[0]),), name=\"historical_input\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fc4d94a-247a-41eb-86a8-e15031271d1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Embedding y LSTM para el texto\n",
    "embedding = Embedding(vocab_size, 128, input_length=seq_length)(text_input)\n",
    "lstm = LSTM(256, return_sequences=False)(embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "854d872e-6df7-4bc4-bea3-c12c709dfed3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenar la salida de LSTM con los datos históricos\n",
    "concat = Concatenate()([lstm, historical_input])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b43d849-5647-4df8-880e-a87fd896559f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Capas densas\n",
    "dense = Dense(128, activation='relu')(concat)\n",
    "output = Dense(vocab_size, activation='softmax')(dense)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5807881d-739e-4d34-9fbc-5a09a1bdf2ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construir el modelo\n",
    "model = tf.keras.models.Model(inputs=[text_input, historical_input], outputs=output)\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Resumen del modelo\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "869328b1-2fbb-484b-a8ff-c8d17a6874fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parámetros de entrenamiento\n",
    "batch_size = 64\n",
    "epochs = 30\n",
    "\n",
    "# Entrenar el modelo\n",
    "history = model.fit(\n",
    "    [input_sequences, historical_features_adjusted],  # Entradas\n",
    "    targets,                                          # Salidas\n",
    "    batch_size=batch_size,\n",
    "    epochs=epochs,\n",
    "    validation_split=0.2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70ecb75f-2e17-4f72-a6df-13db168d5768",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir una función para generar texto\n",
    "def generate_text(seed_text, historical_data, next_words=200):\n",
    "    seed_text += f\" con una probabilidad de victoria del {historical_data[0]*100:.1f}%, \"\n",
    "    seed_text += f\"goles a favor promedio de {historical_data[1]}, y una capacidad del estadio de {historical_data[4]} mil espectadores.\"\n",
    "\n",
    "    for _ in range(next_words):\n",
    "        tokenized_seed = tokenizer.texts_to_sequences([seed_text])[0]\n",
    "        tokenized_seed = pad_sequences([tokenized_seed], maxlen=seq_length, padding='pre')\n",
    "        prediction = model.predict([tokenized_seed, np.array([historical_data])], verbose=0)\n",
    "        predicted_word = tokenizer.index_word.get(np.argmax(prediction), \"\")\n",
    "        seed_text += \" \" + predicted_word\n",
    "    return seed_text\n",
    "\n",
    "# Generar texto de ejemplo\n",
    "seed_text = \"the victory the game\"\n",
    "historical_data_example = [0.85, 3, 1, 2, 81]  # Ejemplo de datos históricos\n",
    "generated_news = generate_text(seed_text, historical_data_example)\n",
    "print(\"Noticia generada:\")\n",
    "print(generated_news)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
